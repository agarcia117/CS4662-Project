{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Prediction\n",
    "## https://www.kaggle.com/c/dog-breed-identification/overview\n",
    "### CS 4662\n",
    "### Spring 2020\n",
    "### Alan Garcia\n",
    "### Ryan Peralta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** In this file we are going to implement the CNN with a lower amount of filters and a greater dropout rate so that the overfitting problem can be solved. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports need to run our code for the Dog Breed project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "\n",
    "#Code so that the notebook is run through the GPU\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "#from tensorflow.keras import backend\n",
    "# \"Sequential\" model lets us to define a stack of neural network layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "# import the \"core\" layers:\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# CNN\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "# import some utilities to transform our data\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell is needed to resize the images to standard and more usable size. It only needs to be run one time at the start of running this project, then it can be commented out for future test runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\ncounter = 0\\nd = \"C:/Users/rpera/Desktop/Spring 2020/CS 4662/Project Data/train\"\\nfor path in os.listdir(d):\\n    full_path = os.path.join(d, path)\\n    if os.path.isfile(full_path):\\n        print(full_path)\\n        img = Image.open(full_path).convert(\\'L\\')\\n        maxsize = (128, 128)\\n        img = img.resize(maxsize, PIL.Image.ANTIALIAS)\\n        img.save(\\'resized_photos/\\'+ str(counter) + \\'.jpg\\')\\n        counter += 1\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "counter = 0\n",
    "d = \"C:/Users/rpera/Desktop/Spring 2020/CS 4662/Project Data/train\"\n",
    "for path in os.listdir(d):\n",
    "    full_path = os.path.join(d, path)\n",
    "    if os.path.isfile(full_path):\n",
    "        print(full_path)\n",
    "        img = Image.open(full_path).convert('L')\n",
    "        maxsize = (128, 128)\n",
    "        img = img.resize(maxsize, PIL.Image.ANTIALIAS)\n",
    "        img.save('resized_photos/'+ str(counter) + '.jpg')\n",
    "        counter += 1\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listForX = []\n",
    "for x in range(0, 10222):\n",
    "    test = mpimg.imread(\"C:/Users/rpera/Desktop/Spring 2020/CS 4662/CS4662-Project/resized_photos/\"+str(x)+\".jpg\")\n",
    "    # test = mpimg.imread(\"/Users/Alan/Desktop/Data_Science_2/final project/resized_photos/\"+str(x)+\".jpg\")\n",
    "    testing = (test.reshape(1, 16384))\n",
    "    listForX.append(testing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert our existing datafram into X by converting the values from a list into an array through numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(listForX)\n",
    "df.values.tolist()\n",
    "X = np.asarray(listForX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the labels.csv into y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"C:/Users/rpera/Desktop/Spring 2020/CS 4662/Project Data/labels.csv\")\n",
    "#y = pd.read_csv(\"/Users/Alan/Desktop/Data_Science_2/final project/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                      id                     breed\n",
       "0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n",
       "1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n",
       "2      001cdf01b096e06d78e9e5112d419397                  pekinese\n",
       "3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n",
       "4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n",
       "...                                 ...                       ...\n",
       "10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n",
       "10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n",
       "10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n",
       "\n",
       "[10222 rows x 2 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the id column from y so that it only contains a vector of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.drop(['id'], axis=1)\n",
    "y['breed'] = pd.factorize(y['breed'])[0]\n",
    "y = y.breed.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split X and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "X_train = X_train.reshape(X_train.shape[0], 128, 128, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 120)\n",
    "y_test = np_utils.to_categorical(y_test, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 128, 128, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 126, 126, 32)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(128,128,1)))\n",
    "print(model.output_shape) # -> (None, 26, 26, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the layers to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 124, 124, 32)\n",
      "(None, 62, 62, 32)\n"
     ]
    }
   ],
   "source": [
    "# more hidden layers:\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Pooling Layer:\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Dropout layer to avoid overfitting\n",
    "model.add(Dropout(0.25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 123008)\n",
      "(None, 128)\n",
      "(None, 120)\n"
     ]
    }
   ],
   "source": [
    "# output Fully connected Dense layers:\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               15745152  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               15480     \n",
      "=================================================================\n",
      "Total params: 15,770,200\n",
      "Trainable params: 15,770,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 120)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6132 samples, validate on 2045 samples\n",
      "Epoch 1/15\n",
      "6132/6132 [==============================] - 138s 22ms/step - loss: 4.9064 - accuracy: 0.0096 - val_loss: 4.7860 - val_accuracy: 0.0112\n",
      "Epoch 2/15\n",
      "6132/6132 [==============================] - 139s 23ms/step - loss: 4.7815 - accuracy: 0.0148 - val_loss: 4.7713 - val_accuracy: 0.0117\n",
      "Epoch 3/15\n",
      "6132/6132 [==============================] - 140s 23ms/step - loss: 4.7639 - accuracy: 0.0144 - val_loss: 4.7565 - val_accuracy: 0.0186\n",
      "Epoch 4/15\n",
      "6132/6132 [==============================] - 138s 22ms/step - loss: 4.7186 - accuracy: 0.0214 - val_loss: 4.6847 - val_accuracy: 0.0269\n",
      "Epoch 5/15\n",
      "6132/6132 [==============================] - 149s 24ms/step - loss: 4.6587 - accuracy: 0.0199 - val_loss: 4.6544 - val_accuracy: 0.0249\n",
      "Epoch 6/15\n",
      "3488/6132 [================>.............] - ETA: 1:09 - loss: 4.6199 - accuracy: 0.0232"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  min_delta=0.01, patience=3)\n",
    "fitted_model = model.fit(X_train, y_train, validation_split=0.25, batch_size=32, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "accuracy = fitted_model.history['acc']\n",
    "#val_accuracy = history.history['val_acc']\n",
    "loss = fitted_model.history['loss']\n",
    "#val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b-', label='Training accuracy')\n",
    "#plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r-', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting based off of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test, verbose=1)\n",
    "print (y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('The accuracy is: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We obtained an accuracy of 2.5%. This might be because we overfit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
